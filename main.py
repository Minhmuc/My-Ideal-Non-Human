from core.llm_interface import ask_llm_with_memory
from core.memory import ConversationBufferMemory
from core.prompt_engineering import clean_input,  exit_intent_confidence
from core.prompts import get_prompt,exit_prompt

if __name__ == "__main__":
    print("ðŸ¤– M.I.N.H: Powering Up...")
    memory = ConversationBufferMemory()
    greeting_message = get_prompt("greeting")
    print(f"ðŸ¤– M.I.N.H: {greeting_message}")
    while True:
        user_input = input("ðŸ‘¤ Báº¡n: ")
        confidence = exit_intent_confidence(user_input)
        if confidence in ("cao"):
            confirm_quit = input(f"ðŸ¤– M.I.N.H: {(exit_prompt())} (y/n): ").strip().lower()
            if confirm_quit in ["y", "yes", "cÃ³"]:
                print(f"ðŸ¤– M.I.N.H: {get_prompt('end')}")
                break
        user_input = clean_input(user_input)
        print("ðŸ¤–M.I.N.H Ä‘ang suy nghÄ©...")
        response = ask_llm_with_memory(user_input,memory)
        print(f"ðŸ¤– M.I.N.H: {response}")